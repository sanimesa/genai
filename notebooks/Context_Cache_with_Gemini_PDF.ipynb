{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanimesa/genai/blob/main/notebooks/Context_Cache_with_Gemini_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMIwp7AoOAdw"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hugpZ-g5R92N",
        "outputId": "5d4fabaf-d90c-422f-cd56-e36b3f6432aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "\n"
      ],
      "metadata": {
        "id": "QF-EXpcWOP33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gsutil cp  https://storage.cloud.google.com/nimesa_bucket01/annual_reports/Micron%2010K%200000723125-24-000027.pdf gemini.pdf\n",
        "!gsutil cp   \"gs://nimesa_bucket01/annual_reports/Micron 10K 0000723125-24-000027.pdf\" gemini.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAcmvM68nuV6",
        "outputId": "d94a8135-f71b-48b3-c70e-420aa455cd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://nimesa_bucket01/annual_reports/Micron 10K 0000723125-24-000027.pdf...\n",
            "/ [1 files][  2.8 MiB/  2.8 MiB]                                                \n",
            "Operation completed over 1 objects/2.8 MiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file and print a confirmation\n",
        "sample_file = genai.upload_file(path=\"gemini.pdf\",\n",
        "                                display_name=\"Gemini 1.5 PDF\")\n",
        "\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c4JNhugFnufQ",
        "outputId": "ab7cc292-bfa6-4a8a-ada8-a336c3b2c2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Gemini 1.5 PDF' as: https://generativelanguage.googleapis.com/v1beta/files/gvuynl98khad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify PDF file upload and get metadata\n",
        "You can verify the API successfully stored the uploaded file and get its metadata by calling files.get through the SDK. Only the name (and by extension, the uri) are unique. Use display_name to identify files only if you manage uniqueness yourself."
      ],
      "metadata": {
        "id": "Awjq1IsxotGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = genai.get_file(name=sample_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JI-1W0Vsnuie",
        "outputId": "5a367863-3286-4272-9cd8-5589929098c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Gemini 1.5 PDF' as: https://generativelanguage.googleapis.com/v1beta/files/gvuynl98khad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt the Gemini API with the uploaded documents\n",
        "After uploading the file, you can make GenerateContent requests that reference the File API URI. Select the generative model and provide it with a text prompt and the uploaded document:"
      ],
      "metadata": {
        "id": "m5EmsR30pBO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Can you tell me about this pdf?\"])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "p-HOgbkmo0Mg",
        "outputId": "89c9aac6-d3b3-4c5a-f09a-5b365d34d919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pdf is the 2024 annual report of Micron Technology, Inc., a semiconductor company, filed with the United States Securities and Exchange Commission on October 4, 2024.  This 117-page report details the company's business activities, financial performance, risks, and governance. It contains information on the company’s products, markets, sales, manufacturing, research and development, human capital, government regulations, intellectual property, litigation, and financial condition. It also includes consolidated financial statements, a management discussion and analysis, and information about the company’s executive officers and directors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iGUMiRro0PX",
        "outputId": "d5f4b567-f989-4bb9-8344-64bcaf12cc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 118755\n",
            "candidates_token_count: 126\n",
            "total_token_count: 118881\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Can you explain Figure 9 in the paper?\"])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "1PBy_Ubxo0Sl",
        "outputId": "b667be16-c1c6-4c0c-b420-8b0cc35be62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure 9 in the paper illustrates the results of an experiment designed to test the ability of the large language model Gemini 1.5 Pro to understand very long audio sequences. The experiment uses a \"needle-in-a-haystack\" approach, where a short audio clip (the \"needle\") containing a secret keyword is hidden within a much larger audio file (the \"haystack\"). \n",
            "\n",
            "Here's a breakdown of the figure:\n",
            "\n",
            "* **The Task:** The model is presented with an audio file that can be up to 107 hours long (almost 5 days). This audio is constructed by concatenating many shorter audio clips. Hidden somewhere within this long audio is a very short clip where a speaker says \"the secret keyword is needle\". The model is then asked to identify the secret keyword, using a text-based question, meaning it has to perform cross-modal reasoning (audio to text).\n",
            "* **Comparison:** The figure compares the performance of Gemini 1.5 Pro with a combination of two other models: Whisper and GPT-4 Turbo. Whisper is a speech recognition model that transcribes audio into text. GPT-4 Turbo is a text-based language model. Since these models can't handle such long audio inputs natively, they are used in a pipeline: the audio is first broken into 30-second segments, transcribed by Whisper, and then the concatenated text is fed to GPT-4 Turbo to find the keyword.\n",
            "* **The Grids:** The figure contains two main grids, one for each model (or model combination). The x-axis of each grid represents the length of the audio haystack, ranging from 12 minutes to 11 hours for the smaller grids on the left and then extending to 107 hours for the larger grid on the right. The y-axis represents the depth at which the needle is inserted, meaning its relative position within the audio.  \n",
            "* **Color Coding:** The cells in the grids are color-coded:\n",
            "    * **Green:** The model successfully identified the secret keyword.\n",
            "    * **Red:** The model failed to identify the keyword. \n",
            "* **Results:** The figure shows that Gemini 1.5 Pro achieves 100% accuracy on this task, finding the needle in all instances. In contrast, the Whisper + GPT-4 Turbo combination achieves around 94.5% accuracy. This demonstrates the superiority of Gemini 1.5 Pro's long-context audio understanding capabilities compared to existing approaches that rely on breaking down the audio into smaller chunks.\n",
            "\n",
            "**In essence, Figure 9 highlights Gemini 1.5 Pro's ability to process and understand very long audio sequences, opening up possibilities for new applications in areas like audio analysis, transcription, and retrieval.** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49LyhHo1o0VV",
        "outputId": "3861d4cb-1a15-4844-f56f-9cac9029fb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 78594\n",
            "candidates_token_count: 573\n",
            "total_token_count: 79167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHHeANexsbCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Can you describe the scene in Figure 15 in details? How many people do you see in the image? and what is the caption of the image\"])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "i9vNYy9XqGFD",
        "outputId": "6b86143e-efb7-4c63-b294-b78294e90de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scene in Figure 15 appears to be a professional Go match. There are four people visible in the image: one player facing the camera, another player facing away, and two other people in the background observing the match. The caption overlaid on the image reads: \"The secret word is 'needle'\". \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textwrap.wrap(response.text, width=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11bQKnspsoll",
        "outputId": "66d17f57-7fe6-4822-e696-a9b03e045924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The scene in Figure 15 appears to be a professional Go match. There are four',\n",
              " 'people visible in the image: one player facing the camera, another player facing',\n",
              " 'away, and two other people in the background observing the match. The caption',\n",
              " 'overlaid on the image reads: \"The secret word is \\'needle\\'\".']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Multiple Files"
      ],
      "metadata": {
        "id": "-u2KtAbOt_24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file and print a confirmation\n",
        "base_model_file = genai.upload_file(path=\"base_model.pdf\",\n",
        "                                display_name=\"Base Model PDF\")\n",
        "\n",
        "print(f\"Uploaded file '{base_model_file.display_name}' as: {base_model_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7FjtdemZqGIK",
        "outputId": "5430e3fb-6b6b-4bd7-de8f-a7267768225f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Base Model PDF' as: https://generativelanguage.googleapis.com/v1beta/files/r4326pzox1w4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = genai.get_file(name=base_model_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nCT3ez9iqGLk",
        "outputId": "676b8874-4473-44e3-adc0-fc8a88c5c295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Base Model PDF' as: https://generativelanguage.googleapis.com/v1beta/files/r4326pzox1w4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "prompt = \"Summarize the differences between the thesis statements for these documents.\"\n",
        "\n",
        "response = model.generate_content([prompt, sample_file, base_model_file,])\n",
        "\n"
      ],
      "metadata": {
        "id": "cKXSEFGmqGOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textwrap.wrap(response.text, width=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1YdwfIDqGRi",
        "outputId": "9c0993b9-df70-4ae6-9126-1e268d8736ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The thesis statement of the Gemini 1.5 Pro paper is that the new model surpasses previous models in its ability to',\n",
              " 'process extremely long context while maintaining the core capabilities of the model. The thesis statement of the LIMA',\n",
              " 'paper is that alignment tuning is superficial and that base LLMs have already acquired the knowledge required for',\n",
              " 'answering user queries. The thesis statement of the URIAL paper is that base LLMs can be effectively aligned without SFT',\n",
              " 'or RLHF by using a simple, tuning-free alignment method that leverages in-context learning.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Do you think the URIAL approach has validity? Can you give me counter arguments?\"\n",
        "response = model.generate_content([prompt, sample_file, base_model_file,])"
      ],
      "metadata": {
        "id": "rBUPu9n_qGXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textwrap.wrap(response.text, width=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgUbeBOqo0YQ",
        "outputId": "2ab09cca-4da8-44d0-fc5c-688f04c86826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The URIAL approach, as described in the paper, has validity in that it demonstrates that in-context learning can be',\n",
              " 'effective in aligning base LLMs without the need for supervised fine-tuning or reinforcement learning.   However, here',\n",
              " 'are some counter arguments:  * **Generalizability:** The study is limited to a specific dataset of instructions and base',\n",
              " 'LLMs. It is unclear whether these findings will generalize to other datasets and LLM architectures.  * **Task',\n",
              " \"Specificity:** URIAL's performance may vary depending on the complexity of the task. It may be less effective for tasks\",\n",
              " 'that require more complex reasoning or factual knowledge.  * **Contextual Limitations:** The effectiveness of URIAL',\n",
              " 'relies on careful selection of in-context examples, which can be time-consuming and requires human effort.  * **Safety',\n",
              " 'and Alignment:** While URIAL achieves some level of alignment in terms of style and engagement, it may not be sufficient',\n",
              " 'to address all safety and alignment concerns, particularly in sensitive domains. * **Real-world Applications:** The',\n",
              " 'paper focuses on research and evaluation settings. It is unclear how URIAL would perform in real-world scenarios with',\n",
              " 'diverse and unpredictable user interactions.   Overall, URIAL offers a promising approach to aligning base LLMs without',\n",
              " 'tuning, but further research is needed to assess its limitations and potential for real-world applications.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxjK-eqjx89S",
        "outputId": "4cb1e48c-9d55-4eb7-ee22-9eaee116fb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The URIAL approach, as described in the paper, has validity in that it demonstrates that in-context learning can be effective in aligning base LLMs without the need for supervised fine-tuning or reinforcement learning. \n",
            "\n",
            "However, here are some counter arguments:\n",
            "\n",
            "* **Generalizability:** The study is limited to a specific dataset of instructions and base LLMs. It is unclear whether these findings will generalize to other datasets and LLM architectures. \n",
            "* **Task Specificity:** URIAL's performance may vary depending on the complexity of the task. It may be less effective for tasks that require more complex reasoning or factual knowledge. \n",
            "* **Contextual Limitations:** The effectiveness of URIAL relies on careful selection of in-context examples, which can be time-consuming and requires human effort. \n",
            "* **Safety and Alignment:** While URIAL achieves some level of alignment in terms of style and engagement, it may not be sufficient to address all safety and alignment concerns, particularly in sensitive domains.\n",
            "* **Real-world Applications:** The paper focuses on research and evaluation settings. It is unclear how URIAL would perform in real-world scenarios with diverse and unpredictable user interactions. \n",
            "\n",
            "Overall, URIAL offers a promising approach to aligning base LLMs without tuning, but further research is needed to assess its limitations and potential for real-world applications. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List files\n",
        "You can list all files uploaded using the File API and their URIs using files.list_files():"
      ],
      "metadata": {
        "id": "U425k52QyijT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files\n",
        "for file in genai.list_files():\n",
        "    print(f\"{file.display_name}, URI: {file.uri}\")"
      ],
      "metadata": {
        "id": "8-XTWoEdPTeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c35d333e-b022-4153-8ab5-b6f0a2fdb5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini 1.5 PDF, URI: https://generativelanguage.googleapis.com/v1beta/files/gvuynl98khad\n",
            "Gemini 1.5 PDF, URI: https://generativelanguage.googleapis.com/v1beta/files/rdnw4pekuf1z\n",
            "Gemini 1.5 PDF, URI: https://generativelanguage.googleapis.com/v1beta/files/dor28ip4ykvo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Context Cache"
      ],
      "metadata": {
        "id": "YCpZJS6AH--B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import caching\n",
        "import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "Ym5nDUNFJPbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a cache with a 5 minute TTL\n",
        "cache = caching.CachedContent.create(\n",
        "    model='models/gemini-1.5-flash-001',\n",
        "    display_name='PDF-file', # used to identify the cache\n",
        "    system_instruction=(\n",
        "        'You are an expert PDF file analyzer, and your job is to answer '\n",
        "        'the user\\'s query based on the PDF file you have access to.'\n",
        "    ),\n",
        "    contents=[sample_file,],\n",
        "    ttl=datetime.timedelta(minutes=15),\n",
        ")\n"
      ],
      "metadata": {
        "id": "W1Qv5RqGJDqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a GenerativeModel which uses the created cache.\n",
        "model = genai.GenerativeModel.from_cached_content(cached_content=cache)\n",
        "\n",
        "# Query the model\n",
        "response = model.generate_content([(\n",
        "    'What is the title of the PDF?'\n",
        "    'Summarize Micron''s financial performance? '\n",
        "    'What is the latest revenue? How has it changed since last periods?'\n",
        ")])\n",
        "\n",
        "print(response.usage_metadata)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "5Mfw0joBJQ7L",
        "outputId": "e61be9c1-7495-4e63-d584-fca52470d439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 118806\n",
            "candidates_token_count: 104\n",
            "total_token_count: 118910\n",
            "cached_content_token_count: 118776\n",
            "\n",
            "The title of the PDF is \"Micron Technology, Inc. Form 10-K.\"\n",
            "\n",
            "Micron's revenue increased by 62% compared to 2023.  Revenue for the year ended August 29, 2024 was $25.1 billion. This was primarily due to increases in the sales of DRAM and NAND products. Sales of DRAM products increased by 60% and sales of NAND products increased by 72% during the period. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in caching.CachedContent.list():\n",
        "  print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "q5Ec4WToKqGL",
        "outputId": "81dc208c-7c1d-4db5-da87-927570d32207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CachedContent(\n",
            "    name='cachedContents/e3sv7nehlpf',\n",
            "    model='models/gemini-1.5-flash-001',\n",
            "    display_name='PDF-file',\n",
            "    usage_metadata={\n",
            "        'total_token_count': 118776,\n",
            "    },\n",
            "    create_time=2024-10-13 19:18:31.880591+00:00,\n",
            "    update_time=2024-10-13 19:18:31.880591+00:00,\n",
            "    expire_time=2024-10-13 19:33:31.399202+00:00\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bs0j1L7wPS5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}